{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gazeNet "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data upload\n",
    "Copy your folder into 'etdata' with .tsv files to the left panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "root = 'etdata'         # The root folder of your trials\n",
    "dataset = 'trials'      # Your folder name\n",
    "format = 'tsv'\n",
    "\n",
    "FILES = glob.glob('%s/%s/*.%s' % (root, dataset, format))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input trial setup\n",
    "\n",
    "Enter measurements for Your eye-tracking-setup.\n",
    "\n",
    "The default values for monitor width and height are for a 24\" 16:9 monitor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "geom = {\n",
    "    'screen_width': 53.1,       # Screen width in cm\n",
    "    'screen_height': 29.8,      # Screen height in cm\n",
    "    'display_width_pix': 1920,  # Screen width in pixels\n",
    "    'display_height_pix': 1080, # Screen height in pixels\n",
    "    'eye_distance': 60,         # Viewing distance in cm\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdir/model_final/models/gazeNET_0004_00003750.pth.tar\n",
      "Loading model: logdir/model_final/models/gazeNET_0004_00003750.pth.tar\n",
      "done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "gazeNET(\n",
       "  (conv_stack): Sequential(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv2d(1, 8, kernel_size=(2, 11), stride=(1, 1), padding=(1, 5), bias=False)\n",
       "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
       "      (3): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv2d(8, 8, kernel_size=(2, 11), stride=(1, 1), padding=(1, 5), bias=False)\n",
       "      (1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): Hardtanh(min_val=0, max_val=20, inplace=True)\n",
       "      (3): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (rnn_stack): Sequential(\n",
       "    (gru1): BatchRNN(\n",
       "      (rnn): GRU(32, 64, bias=False, batch_first=True, bidirectional=True)\n",
       "      (batch_norm_op): SequenceWise (\n",
       "      BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
       "      (dropout_op): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (gru2): BatchRNN(\n",
       "      (rnn): GRU(64, 64, bias=False, batch_first=True, bidirectional=True)\n",
       "      (batch_norm_op): SequenceWise (\n",
       "      BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
       "      (dropout_op): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "    (gru3): BatchRNN(\n",
       "      (rnn): GRU(64, 64, bias=False, batch_first=True, bidirectional=True)\n",
       "      (batch_norm_op): SequenceWise (\n",
       "      BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
       "      (dropout_op): Dropout(p=0.25, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): SequenceWise (\n",
       "    Linear(in_features=64, out_features=3, bias=False))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "## model configuration\n",
    "from utils_lib import utils\n",
    "\n",
    "dev = False\n",
    "model_dir = 'model_final'\n",
    "model_name = 'gazeNET_0004_00003750'\n",
    "model_name = '%s.pth.tar'%model_name\n",
    "\n",
    "logdir =  os.path.join('logdir', model_dir)\n",
    "fname_config = os.path.join(logdir, 'config.json')\n",
    "configuration = utils.Config(fname_config)\n",
    "config = configuration.params\n",
    "\n",
    "config['split_seqs']=False\n",
    "config['augment']=False\n",
    "config['batch_size']=1\n",
    "cuda = False\n",
    "num_classes = len(config['events'])\n",
    "\n",
    "## load model\n",
    "from model import gazeNET as gazeNET\n",
    "import model as model_func\n",
    "\n",
    "model = gazeNET(config, num_classes)\n",
    "model_func.load(model, model_dir, config, model_name)\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenz/gazeNet/utils_lib/etdata.py:145: DtypeWarning: Columns (37,38,65,66,67,68,69,70,72,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = pd.read_csv(file, sep='\\t', header=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Kreuze_Random Recording1.tsv\n",
      "[FP], n_samples: 1, dur: 12.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7839/2652162367.py:59: DtypeWarning: Columns (37,38,65,66,67,68,69,70,72,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(fpath, sep='\\t')\n",
      "/home/lorenz/gazeNet/utils_lib/etdata.py:145: DtypeWarning: Columns (37,38,65,66,67,68,69,70,72,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_data = pd.read_csv(file, sep='\\t', header=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting Kreuze_Random Recording2.tsv\n",
      "[FP], n_samples: 1, dur: 8.93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7839/2652162367.py:59: DtypeWarning: Columns (37,38,65,66,67,68,69,70,72,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(fpath, sep='\\t')\n"
     ]
    }
   ],
   "source": [
    "## load data\n",
    "from utils_lib.etdata import ETData, tsv_to_npy\n",
    "from utils_lib.data_loader import EMDataset, GazeDataLoader\n",
    "\n",
    "for fpath in FILES:\n",
    "    fname = os.path.basename(fpath)\n",
    "    if format == 'tsv':\n",
    "        x_px, y_px, X_test = tsv_to_npy(fpath, geom)\n",
    "    else:\n",
    "        X_test = np.load(fpath)\n",
    "\n",
    "    _status = np.isnan(X_test['x']) | \\\n",
    "            np.isnan(X_test['y']) | \\\n",
    "            ~np.in1d(X_test['evt'], config['events'])\n",
    "    X_test['status'] = ~_status\n",
    "    test_dataset = EMDataset(config = config, gaze_data = [X_test])\n",
    "    n_samples = len(test_dataset)\n",
    "    test_loader = GazeDataLoader(test_dataset, batch_size=config['batch_size'],\n",
    "                                num_workers=0,\n",
    "                                shuffle=False)\n",
    "    \n",
    "    ## label data\n",
    "    from utils_lib.ETeval import run_infer\n",
    "    kwargs = {\n",
    "        'cuda': False,\n",
    "        'use_tqdm': False,\n",
    "        'eval': False,\n",
    "    }\n",
    "\n",
    "    print (\"Predicting %s\" % fname)\n",
    "    _gt, _pr, pr_raw = run_infer(model, n_samples, test_loader, **kwargs)\n",
    "\n",
    "    ## postprocessing\n",
    "\n",
    "    # revert to kartesian\n",
    "    if format == 'tsv':\n",
    "        X_test['x'] = x_px\n",
    "        X_test['y'] = y_px\n",
    "\n",
    "    #glue back the predictions\n",
    "    import copy\n",
    "    _data_pr = copy.deepcopy(test_dataset.data)\n",
    "    for _d, _pred in zip(_data_pr, pr_raw):\n",
    "        _d['evt'] = 0\n",
    "        _d['evt'][1:] = np.argmax(_pred, axis=1)+1\n",
    "    _data_pr = pd.concat([pd.DataFrame(_d) for _d in _data_pr]).reset_index(drop=True)\n",
    "    _data = pd.DataFrame(X_test)\n",
    "    _data = _data.merge(_data_pr, on='t', suffixes=('', '_pred'), how='left')\n",
    "    _data['evt'] = _data['evt_pred'].replace({np.nan:0})\n",
    "\n",
    "    etdata_pr = ETData()\n",
    "    etdata_pr.load(_data[['t', 'x', 'y', 'status', 'evt']].values, **{'source':'np_array'})\n",
    "\n",
    "    sdir = '%s/%s_gazeNet'%(root, dataset)\n",
    "    if not os.path.exists(sdir):\n",
    "        os.makedirs(sdir)\n",
    "    spath = '%s/%s'%(sdir, fname.replace('.tsv', ''))\n",
    "    if format == 'tsv':     # add predictions to the original data\n",
    "        data = pd.read_csv(fpath, sep='\\t')\n",
    "        data = data.merge(_data['evt'], left_index=True, right_index=True)\n",
    "        data.to_csv(spath, sep='\\t', index=False)\n",
    "    else:\n",
    "        etdata_pr.save(spath)\n",
    "    etdata_pr.plot_px(show=False, save=True, spath='%s'%spath)\n",
    "    etdata_pr.plot_xy(show=False, save=True, spath='%s'%spath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
